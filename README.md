
# ğŸš€ Designing a Scalable Cryptocurrency Data Pipeline Using Azure

> Automating cryptocurrency data extraction, transformation, and analytics for optimized portfolio management using Azure Cloud and Databricks.

---

## ğŸ“˜ Project Overview

IntelloBank aims to modernize its cryptocurrency portfolio management by building a production-grade, **cloud-native data pipeline**. This pipeline ingests real-time data from the **CoinGecko API**, transforms it using **Databricks & Delta Lake**, and serves actionable insights through **Azure SQL** and **Power BI** dashboards.

This project leverages **Azureâ€™s cloud ecosystem** to ensure:
- ğŸ”„ End-to-end automation
- âš¡ Scalable data handling
- âœ… High data quality
- ğŸ“Š Real-time analytical capabilities

---

## ğŸ¯ Objectives

- Extract real-time cryptocurrency data from **CoinGecko API**
- Clean, transform, and validate data using **Azure Databricks**
- Store raw, intermediate, and refined data using **Medallion Architecture**
- Automate workflows with **Azure Data Factory**
- Deliver insights through **Power BI dashboards**

---

## ğŸ§± Architecture Overview

The pipeline follows a **Medallion Architecture** (Bronze â†’ Silver â†’ Gold) within Azure:

- **Bronze Layer:**  
  Raw data ingested from CoinGecko API â†’ stored in **Azure Data Lake Gen2**

- **Silver Layer:**  
  Cleaned, validated, and structured data â†’ processed with **PySpark, Delta Live Tables**

- **Gold Layer:**  
  Business-ready datasets (volatility, trends, correlations) â†’ stored in **Azure SQL Database**

- **Presentation:**  
  Connected to **Power BI** for dashboards and visual insights

---

## ğŸ”§ Tech Stack

| Component              | Purpose                                             |
|------------------------|-----------------------------------------------------|
| ğŸ Python              | API integration, ETL scripting                     |
| â˜ï¸ Azure Data Factory  | Workflow orchestration                             |
| ğŸ§  Azure Databricks    | Data processing with Delta Lake & Autoloader       |
| ğŸ“¦ Azure Data Lake     | Raw & intermediate data storage                    |
| ğŸ—ƒ Azure SQL Database  | Gold layer storage for business consumption        |
| ğŸ“Š Power BI            | Real-time dashboards & reporting                   |
| ğŸ” Azure Key Vault     | Secure storage of credentials & API keys          |

---

## ğŸ“ˆ Key Features

- ğŸ” **Automated ETL:** No manual intervention needed
- â± **Real-Time Ingestion:** Scheduled extraction jobs from CoinGecko API
- ğŸ“Š **Business-Ready Analytics:** Correlation matrices, volatility indices, trend tracking
- ğŸ” **Power BI Dashboards:** Real-time and historical insights
- ğŸ’¾ **Historical Data Management:** Time travel enabled by Delta Lake
- âš™ **Resilience & Monitoring:** Built-in retries, alerts, and execution logs

---

## ğŸ“š Learning Outcomes

This project offered hands-on exposure to:

- Cloud-native data engineering on Azure
- API-driven data ingestion
- Modern data lake architectures (Bronze/Silver/Gold)
- Azure-native orchestration and security
- Scalable data transformation pipelines using PySpark

---

## ğŸ”® Future Enhancements

- Integrate **machine learning models** for price prediction
- Add **alternative data sources** (e.g., social sentiment)
- Real-time **event-driven alerting**
- Implement **streaming ingestion pipelines**

---

## ğŸ¦ Business Impact

âœ… Improved investment decision-making  
âœ… Faster market response  
âœ… Reliable, scalable, cost-efficient architecture  
âœ… Reduced manual effort and operational risks  

---

## ğŸ“Œ Authors & Credits

**Project Team:**  
Adeseye Ogunsina - Amdari Data Engineering Consultant  
Special thanks to [CoinGecko](https://coingecko.com) for open API access
